sum(fit.c.res)
sum(w.c) /sum(fit.c.res)
fit[[1]][1] + 3 * fit[[1]][2]
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ wt, mtcars)
fit[[1]][1] + 3 * fit[[1]][2]
summary(fit)
fit[[1]][1] + 3 * fit[[1]][2]
summary(fit)
fit[[1]][1] + 3 /fit[[1]][2]
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
fit2 <- lm(mpg ~ factor(cyl), mtcars)
summary(fit2)
plot(fit2)
summary(fit3)
data(mtcars)
fit3 <- lm(mpg ~ factor(cyl)*wt, mtcars)
summary(fit3)
fit3
summary(fit3)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
lm.influence(fit)$hat
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
lm.influence(fit)$hat
dfbetas(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
# Give the hat diagonal for the most influential point
fit <- lm(y ~ x)
hatvalues(fit)
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
l1<-lm(mpg ~ factor(cyl)+wt, data = mtcars)
l2<-lm(mpg ~ factor(cyl)*wt, data = mtcars)
library(lmtest)
lrtest(l2,l1)
library(lmtest)
install.packages("lmtest")
l1<-lm(mpg ~ factor(cyl)+wt, data = mtcars)
l2<-lm(mpg ~ factor(cyl)*wt, data = mtcars)
library(lmtest)
lrtest(l2,l1)
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
Ho is rejected, because TS(t = `r th$statistic`) > qt(1-alpha,`r th$parameter`)( = `r qt(1-alpha,th$parameter)`).
install.packages("swirl")
library(swirl)
swirl()
plot(child ~ parent, galton)
exit
q
plot(jitter(child,4) ~ parent,galton)"
exit
q
q
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
install.packages("randomForest")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(caret)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(randomForest)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
plot(x = trainSet[, names], y = trainSet$classe)
names
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(testDataURL)), na.strings = c("NA", ""))
#clean up data
NAs <- apply(trainingData, 2, function(x) {
sum(is.na(x))
})
cleanTrainingData <- trainingData[, which(NAs == 0)]
cleanTestData <- testData[, which(NAs == 0)]
dim(cleanTrainingData)
dim(cleanTestData)
##Using 70% for training and 30% for Cross Validation. None generated for testing since that set is already provided.
trainIndex <- createDataPartition(y = cleanTrainingData$classe, p = 0.7, list = FALSE)
trainSet <- cleanTrainingData[trainIndex, ]
crossValidationSet <- cleanTrainingData[-trainIndex, ]
# Removing variables that have time, or names in it, also new_window.
# Columns 1..6
removeIndex <- as.integer(c(1, 2, 3, 4, 5, 6))
trainSet <- trainSet[, -removeIndex]
testSet <- cleanTestData[, -removeIndex]
crossValidationSet <- crossValidationSet[, -removeIndex]
dim(trainSet)
dim(testSet)
dim(crossValidationSet)
names <- colnames(trainSet)
names <- names[-length(names)]
names
qplot(trainSet[, names],trainSet$classe,colour=trainSet$classe,data=trainSet)
qplot(,trainSet$classe,colour=trainSet$classe,data=trainSet)
plot(x = trainSet[, names], y = trainSet$classe)
head(trainSet)
qplot(,trainSet$classe,colour=trainSet[, names],data=trainSet)
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(testDataURL)), na.strings = c("NA", ""))
#clean up data
NAs <- apply(trainingData, 2, function(x) {
sum(is.na(x))
})
cleanTrainingData <- trainingData[, which(NAs == 0)]
cleanTestData <- testData[, which(NAs == 0)]
dim(cleanTrainingData)
dim(cleanTestData)
##Using 70% for training and 30% for Cross Validation. None generated for testing since that set is already provided.
trainIndex <- createDataPartition(y = cleanTrainingData$classe, p = 0.7, list = FALSE)
trainSet <- cleanTrainingData[trainIndex, ]
crossValidationSet <- cleanTrainingData[-trainIndex, ]
# Removing variables that have time, or names in it, also new_window.
# Columns 1..6
removeIndex <- as.integer(c(1, 2, 3, 4, 5, 6))
trainSet <- trainSet[, -removeIndex]
testSet <- cleanTestData[, -removeIndex]
crossValidationSet <- crossValidationSet[, -removeIndex]
dim(trainSet)
dim(testSet)
dim(crossValidationSet)
####
library(randomForest)
library(caret)
set.seed(13333)
fitControl<-trainControl(method="cv", number=5, allowParallel=T, verbose=T)
modelFit <- train(trainSet$classe ~ ., data = trainSet, method = "rf", trControl = fitControl)
plot(modelFit)
inVarImp <- createDataPartition(y = trainSet$classe, p = 0.1, list = F)
varImpSub <- trainSet[inVarImp, ]
varImpRF <- train(classe ~ ., data = varImpSub, method = "rf")
varImpObj <- varImp(varImpRF)
plot(varImpObj, main = "Variable Importance of Top 52", top = 52)
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(testDataURL)), na.strings = c("NA", ""))
#clean up data
NAs <- apply(trainingData, 2, function(x) {
sum(is.na(x))
})
cleanTrainingData <- trainingData[, which(NAs == 0)]
cleanTestData <- testData[, which(NAs == 0)]
dim(cleanTrainingData)
sum(complete.cases(cleanTrainingData))
head(cleanTrainingData)
summary(cleanTrainingData)
dim(cleanTrainingData)
sum(complete.cases(cleanTrainingData))
head(cleanTrainingData)
summary(cleanTrainingData)
Near_Zero_val <- nearZeroVar(cleanTrainingData)
Near_Zero_val <- nearZeroVar(cleanTrainingData)
Near_Zero_val <- nearZeroVar(cleanTrainingData)
summary(cleanTrainingData)
Near_Zero_val <- nearZeroVar(cleanTrainingData)
Near_Zero_val
md5 R-3.1.2-mavericks.pkg
setwd("~/git/GTMachineLearning_Assignment_1/poker")
setwd("~/git/GTMachineLearning_Assignment_1/poker")
#setwd("~/class/GTMachineLearning_Assignment_1/poker")
train <- read.csv("train.csv")
head(train)
#labels = as.factor(train$hand)
#train = train[,1:10]
#head(train)
library(rpart)
CART.fit <- rpart(hand ~., data=train,
control=rpart.control(minsplit=2, minbucket=1, cp=0.001))
summary(CART.fit)
summary(CART.fit)
#plot(CART.fit)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(CART.fit)
plotcp(CART.fit)
ptree <- prune(CART.fit,cp=CART.fit$cptable[which.min(CART.fit$cptable[,"xerror"]),"CP"])
plotcp(ptree)
fancyRpartPlot(ptree)
setwd("~/git/GTMachineLearning_Assignment_1/poker")
#setwd("~/class/GTMachineLearning_Assignment_1/poker")
train <- read.csv("train.csv")
head(train)
#labels = as.factor(train$hand)
#train = train[,1:10]
#head(train)
library(rpart)
CART.fit <- rpart(hand ~., data=train,
control=rpart.control(minsplit=2, minbucket=1, cp=0.001))
summary(CART.fit)
#plot(CART.fit)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
#fancyRpartPlot(CART.fit)
#plotcp(CART.fit)
ptree <- prune(CART.fit,cp=CART.fit$cptable[which.min(CART.fit$cptable[,"xerror"]),"CP"])
#plotcp(ptree)
#fancyRpartPlot(ptree)
test <- read.csv("test.csv")
head(test)
#Get rid of ID column
test = test[,2:11]
head(test)
prediction <- predict(ptree, newdata=test)
summary(prediction)
head(prediction)
library(caret)
sub <- read.csv("sampleSubmission.csv")
sub = sub[,2:2]
head(sub
#http://www.kaggle.com/c/poker-rule-induction/data
setwd("~/class/GTMachineLearning_Assignment_1/poker")
#setwd("~/git/GTMachineLearning_Assignment_1/poker")
train = read.csv("train.csv")
test = read.csv("test.csv")
#Get rid of ID column
test = test[,2:11]
dim(test)
#Separate labels from training set
labels = as.factor(train$hand)
train = train[,1:10]
#Split training set into partial training set and validation set
part_train = train[1:18000,]
valid = train[-1:-18000,]
labels_part = labels[1:18000]
valid_labels = labels[-1:-18000]
# descion tree
library(rpart)
mycontrol = rpart.control(cp = 0.1, xval = 20)
fit = rpart(labels_part~.,method="class", data=part_train,control = mycontrol)
#fit$cptable
#printcp(fit) # display the results
#plotcp(fit) # visualize cross-validation results
#summary(fit) # detailed summary of splits
ptree <- prune(fit,cp=fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#plotcp(ptree) # visualize cross-validation results
prediction <- predict(fit, valid, type = "class")
summary(prediction)
confusionMatrix(prediction,valid_labels)
tree_pred = predict(fit, newdata=test, type="class")
summary(tree_pred)
summary(tree_pred)
#http://www.kaggle.com/c/poker-rule-induction/data
setwd("~/class/GTMachineLearning_Assignment_1/poker")
#setwd("~/git/GTMachineLearning_Assignment_1/poker")
train = read.csv("train.csv")
test = read.csv("test.csv")
#Get rid of ID column
test = test[,2:11]
dim(test)
#Separate labels from training set
labels = as.factor(train$hand)
train = train[,1:10]
#Split training set into partial training set and validation set
part_train = train[1:18000,]
valid = train[-1:-18000,]
labels_part = labels[1:18000]
valid_labels = labels[-1:-18000]
# descion tree
library(rpart)
mycontrol = rpart.control(cp = 0.1, xval = 20)
fit = rpart(labels_part~.,method="class", data=part_train,control = mycontrol)
#fit$cptable
#printcp(fit) # display the results
#plotcp(fit) # visualize cross-validation results
#summary(fit) # detailed summary of splits
ptree <- prune(fit,cp=fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])
#plotcp(ptree) # visualize cross-validation results
head(test)
prediction <- predict(ptree, valid, type = "class")
confusionMatrix(prediction,valid_labels)
tree_pred = predict(ptree, newdata=test, type="class")
summary(tree_pred)
sub =  read.csv("sub.csv")
head(sub)
val = sub[,2:2]
head(val)
head(sub)
head(val)
head(sub$hand)
test_labels = as.factor(sub$hand)
confusionMatrix(tree_pred,test_labels)
dim(tree_pred)
count(tree_pred)
valid_labels
test_labels
valid_labels
train <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data",
header=FALSE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
summary(train)
head(train)
test <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data",
header=FALSE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
summary(test)
head(test)
dim(train)
dim(test)
# add header
names(test) <- c("C1","S1","C2","S2","C3","S3","C4","S4","C5","S5","CLASS")
names(train) <- c("C1","S1","C2","S2","C3","S3","C4","S4","C5","S5","CLASS")
head(test)
head(train)
valid_labels
setwd("~/git/GTMachineLearning_Assignment_1/rawData")
setwd("~/git/GTMachineLearning_Assignment_1/rawData")
head(test)
head(train)
write.csv(test, file = "test.csv")
write.csv(train, file = "train.csv")
setwd("~/git/GTMachineLearning_Assignment_1/rawData")
train = read.csv("train.csv")
test = read.csv("test.csv")
setwd("~/git/GTMachineLearning_Assignment_1/rawData")
train = read.csv("train.csv")
test = read.csv("test.csv")
head(train)
head(test)
head(train)
head(test)
test = test[,2:11]
dim(test)
train = train[,2:11]
dim(train)
head(train)
head(test)
head(train)
setwd("~/git/GTMachineLearning_Assignment_1/rawData")
train = read.csv("train.csv")
test = read.csv("test.csv")
test = test[,2:12]
train = train[,2:12]
dim(test)
dim(train)
head(train)
head(test)
trainlabels = as.factor(train$CLASS)
train = train[,1:10]
dim(train)
testlabels = as.factor(test$CLASS)
test = test[,1:10]
dim(test)
dim(train)
head(train)
head(test)
part_train = train[1:18000,]
valid = train[-1:-18000,]
labels_part = labels[1:18000]
valid_labels = labels[-1:-18000]
part_train = train[1:18000,]
valid = train[-1:-18000,]
labels_part = trainlabels[1:18000]
valid_labels = trainlabels[-1:-18000]
library(rpart)
mycontrol = rpart.control(cp = 0.1, xval = 20)
tree = rpart(labels_part~.,method="class", data=part_train,control = mycontrol)
plotcp(tree)
set.seed(12)
tree = rpart(labels_part~.,method="class", data=part_train)
plotcp(tree)
plotcp(tree)
plotcp(tree)
set.seed(12)
mycontrol = rpart.control(minsplit=2, minbucket=1, cp=0.001)
tree = rpart(labels_part~.,method="class", data=part_train,control = mycontrol)
plotcp(tree)
summary(fit)
summary(tree)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(tree)
ptree <- prune(tree,cp=tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"])
plotcp(ptree)
plotcp(tree)
plotcp(tree)
ptree <- prune(tree,cp=tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"])
plotcp(ptree)
fancyRpartPlot(ptree)
plotcp(tree)
pfit<- prune(tree, cp=0.0022)
plotcp(pfit)
fancyRpartPlot(pfit)
plotcp(pfit)
pfit<- prune(tree, cp=0.0033)
plotcp(pfit)
fancyRpartPlot(pfit)
ptree <- prune(tree,cp=tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"])
set.seed(12)
mycontrol = rpart.control(minsplit=30, minbucket=1, cp=0.001)
tree = rpart(labels_part~.,method="class", data=part_train,control = mycontrol)
plotcp(tree)
fancyRpartPlot(tree)
ptree <- prune(tree,cp=tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"])
plotcp(ptree)
fancyRpartPlot(ptree)
set.seed(12)
tree = randomForest(labels_part~., data=part_train, nodesize=1, ntree=500, mtry=4)
library(caret)
library(randomForest)
set.seed(12)
tree = randomForest(labels_part~., data=part_train, nodesize=1, ntree=500, mtry=4)
plot(tree)
set.seed(12)
mycontrol = rpart.control(minsplit=3, minbucket=1, cp=0.001)
tree = rpart(labels_part~.,method="class", data=part_train,control = mycontrol)
plotcp(tree)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(tree)
ptree <- prune(tree,cp=tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"])
pfit<- prune(tree, cp=0.0022)
plotcp(ptree)
plotcp(pfit)
fancyRpartPlot(pfit)
tree_pred = predict(pfit, newdata=valid, type="class")
confusionMatrix(tree_pred,valid_labels)
pred = predict(pfit, newdata=test, type="class")
confusionMatrix(pred,test_labels)
pred = predict(pfit, newdata=test, type="class")
confusionMatrix(pred,testlabels)
